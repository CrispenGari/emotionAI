{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Emotions_Sentiment_Analyisis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1utmDx96W_"
      },
      "source": [
        "### Emotions From Text.\n",
        "\n",
        "In this notebook we are going to create a pytorch model using torchtext and our custom dataset that identifies emotions that are in a given sentence.\n",
        "\n",
        "### Emotions:\n",
        "````\n",
        "üòû -> sadness\n",
        "üò® -> fear\n",
        "üòÑ -> joy\n",
        "üòÆ -> surprise\n",
        "üòç -> love\n",
        "üò† -> anger\n",
        "````\n",
        "\n",
        "We are going to use our custom dataset that we will load from my google drive.\n",
        "\n",
        "### Structure of the data.\n",
        "\n",
        "We have three files which are:\n",
        "\n",
        "```\n",
        "* test.txt\n",
        "* train.txt\n",
        "* val.txt\n",
        "```\n",
        "\n",
        "And each of these file contains lines with a respective lable. The text in these files looks as follows:\n",
        "\n",
        "```txt\n",
        "im feeling quite sad and sorry for myself but ill snap out of it soon;sadness\n",
        "i feel like i am still looking at a blank canvas blank pieces of paper;sadness\n",
        "i feel like a faithful servant;love\n",
        "```\n",
        "\n",
        "We will process these text file to come up with json files which is easy to work with when creating our own dataset using torchtext. The following files will be created\n",
        "\n",
        "* train.json\n",
        "* test.json\n",
        "* validation.json\n",
        "\n",
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwW3ZpRa8M16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1994d08e-a854-46e0-a483-1a4f387d6b17"
      },
      "source": [
        "import json\n",
        "import time\n",
        "from prettytable import PrettyTable\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import torch, os, random\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3t_igXyM9t1"
      },
      "source": [
        "### Setting seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IMd2xVfNARk"
      },
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r80FOaPcCTdU"
      },
      "source": [
        "### Mounting my Google Drive\n",
        "\n",
        "As our data is in the google drive we need to mount the drive so that we will easly access the data here in google colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fUj1C0PCXzk",
        "outputId": "2950bcc8-7fef-4d62-ef9d-6ab6882103df"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Path to where the data is located\n",
        "\n",
        "In the following code cell we are going to define a variable that stores the data pathe"
      ],
      "metadata": {
        "id": "PYOau3UQUod5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVOh6a73CGIt",
        "outputId": "98f7ee32-8e26-41d5-81a7-52cd45fd22b7"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/NLP Data/emotions-nlp'\n",
        "os.path.exists(data_path)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmGTqOGmDdzo"
      },
      "source": [
        "### Loading files lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jgn2_KHCOsX"
      },
      "source": [
        "with open(os.path.join(data_path, 'test.txt'), 'r') as reader:\n",
        "  test_data = reader.read().splitlines()\n",
        "with open(os.path.join(data_path, 'val.txt'), 'r') as reader:\n",
        "  valid_data = reader.read().splitlines()\n",
        "with open(os.path.join(data_path, 'train.txt'), 'r') as reader:\n",
        "  train_data = reader.read().splitlines()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdDhHO4jDixm"
      },
      "source": [
        "### Creating `.json` file from these loaded list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwZ1FrzZClGD"
      },
      "source": [
        "train_data_dicts = []\n",
        "test_data_dicts = []\n",
        "valid_data_dicts = []\n",
        "\n",
        "emotions = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise' ]\n",
        "emotions_dict = dict([(v, i) for (i, v) in enumerate(emotions)])\n",
        "\n",
        "for line in test_data:\n",
        "  text, emotion = line.split(';')\n",
        "  test_data_dicts.append({\n",
        "      'text': text,\n",
        "      \"emotion_text\": emotion,\n",
        "      \"emotion\": emotions_dict.get(emotion)\n",
        "  })\n",
        "\n",
        "for line in train_data:\n",
        "  text, emotion = line.split(';')\n",
        "  train_data_dicts.append({\n",
        "      'text': text,\n",
        "      \"emotion_text\": emotion,\n",
        "      \"emotion\": emotions_dict.get(emotion)\n",
        "  })\n",
        "\n",
        "for line in valid_data:\n",
        "  text, emotion = line.split(';')\n",
        "  valid_data_dicts.append({\n",
        "      'text': text,\n",
        "      \"emotion_text\": emotion,\n",
        "      \"emotion\": emotions_dict.get(emotion)\n",
        "  })"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the data to `json` files"
      ],
      "metadata": {
        "id": "uFurAtScU85l"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiNlTgHMGlJ5",
        "outputId": "03ddcf74-f415-45b8-9c16-40452ba93dbe"
      },
      "source": [
        "test_path = 'test.json'\n",
        "train_path = 'train.json'\n",
        "valid_path = 'valid.json'\n",
        "\n",
        "base_path = '/content/drive/MyDrive/NLP Data/emotions-nlp/json'\n",
        "if not os.path.exists(base_path):\n",
        "  os.makedirs(base_path)\n",
        "  \n",
        "file_object = open(os.path.join(base_path, train_path), 'w')\n",
        "for line in train_data_dicts:\n",
        "  file_object.write(json.dumps(line))\n",
        "  file_object.write('\\n')\n",
        "file_object.close()\n",
        "print(\"train.json created\")\n",
        "\n",
        "file_object = open(os.path.join(base_path, test_path), 'w')\n",
        "for line in test_data_dicts:\n",
        "  file_object.write(json.dumps(line))\n",
        "  file_object.write('\\n')\n",
        "file_object.close()\n",
        "print(\"test.json created\")\n",
        "\n",
        "file_object = open(os.path.join(base_path, valid_path), 'w')\n",
        "for line in valid_data_dicts:\n",
        "  file_object.write(json.dumps(line))\n",
        "  file_object.write('\\n')\n",
        "file_object.close()\n",
        "print(\"valid.json created\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train.json created\n",
            "test.json created\n",
            "valid.json created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdTT0Wf-FkQM"
      },
      "source": [
        "### Checking how many example do we have for each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o__Q9Eg-ElOr",
        "outputId": "b7aae173-29e0-4e22-88d2-e3e5bd4f0e6d"
      },
      "source": [
        "def tabulate(column_names, data, title):\n",
        "  table = PrettyTable(column_names)\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)\n",
        "\n",
        "data_rows =[\"training\", len(train_data_dicts) ], [\"testing\", len(test_data_dicts) ], [\"validation\", len(valid_data_dicts) ]\n",
        "title = \"EXAMPLES IN EACH SET\"\n",
        "column_data = \"SET\", \"EXAMPLES\"\n",
        "tabulate(column_data,data_rows, title )"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|  EXAMPLES IN EACH SET |\n",
            "+------------+----------+\n",
            "|    SET     | EXAMPLES |\n",
            "+------------+----------+\n",
            "|  training  |  16000   |\n",
            "|  testing   |   2000   |\n",
            "| validation |   2000   |\n",
            "+------------+----------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koSwViS6GgpG"
      },
      "source": [
        "### Preparing the fields\n",
        "Now that our `.json` files of all the sets looks as follows:\n",
        "\n",
        "```json\n",
        "{\"text\": \"i feel a little mellow today\", \"emotion_text\": \"joy\", \"emotion\": 2}\n",
        "```\n",
        "We are now ready to create the fields ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8gRW0MvF5zg"
      },
      "source": [
        "from torchtext.legacy import data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDdVTrC6IN6U"
      },
      "source": [
        "We are going to pass `include_lengths=True` to the text Field because we are using padding padded sequences in this notebook. In the label Field we have to specify the datatype as a LongTensor. This is because when doing multiclass classfication pytorch expects the datatype to be a long tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keaWKPOYIlji"
      },
      "source": [
        "TEXT = data.Field(\n",
        "    tokenize=\"spacy\",\n",
        "    include_lengths = True,\n",
        "    tokenizer_language = 'en_core_web_sm'\n",
        ")\n",
        "LABEL = data.LabelField()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2-nJI3jJ1aX"
      },
      "source": [
        "### Creating Field"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42KSs4x4Jqn7"
      },
      "source": [
        "fields ={\n",
        "    \"emotion_text\": (\"emotion\", LABEL),\n",
        "    \"text\": (\"text\", TEXT)\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j4EktWIKNTe"
      },
      "source": [
        "### Now we have to create our datasets.\n",
        "\n",
        "We are going to use the `TabularDataset` to create sets of data for validation, training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KeetcfEKI4T"
      },
      "source": [
        "train_data, test_data, valid_data = data.TabularDataset.splits(\n",
        "    path=base_path,\n",
        "    train=train_path,\n",
        "    test=test_path,\n",
        "    validation = valid_path,\n",
        "    format=train_path.split('.')[-1],\n",
        "    fields=fields\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKXy_ncvKz3w",
        "outputId": "ceae74dd-d6a9-4847-88e8-9beaf18fc7ab"
      },
      "source": [
        "print(vars(train_data.examples[2]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'emotion': 'anger', 'text': ['i', 'm', 'grabbing', 'a', 'minute', 'to', 'post', 'i', 'feel', 'greedy', 'wrong']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GngtXNqBLKcY"
      },
      "source": [
        "### Loading the pretrained word embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_U8PMxUK93K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4142628-edd6-4a9c-9897-7d4140707206"
      },
      "source": [
        "MAX_VOCAB_SIZE = 25_000\n",
        "TEXT.build_vocab(\n",
        "    train_data,\n",
        "    max_size = MAX_VOCAB_SIZE,\n",
        "    vectors = \"glove.6B.100d\",\n",
        "    unk_init = torch.Tensor.normal_\n",
        ")\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:40, 5.37MB/s]                           \n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 399999/400000 [00:22<00:00, 17659.39it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAIgg0FoMv5W"
      },
      "source": [
        "### Device"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YwSNu3PMx_8"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXmABbFBLYNc"
      },
      "source": [
        "### Now lets create iterators.\n",
        "\n",
        "For this we are going to use my fav ``BucketIterator`` to create iterators for each set.\n",
        "\n",
        "**Note:** - we have to pass a `sort_key` and `sort_within_batch=True` since we are using packed padded sequences otherwise it wont work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL3roEBULWeD"
      },
      "source": [
        "sort_key = lambda x: len(x.text)\n",
        "BATCH_SIZE = 64\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data),\n",
        "    device = device,\n",
        "    batch_size = BATCH_SIZE,\n",
        "    sort_key = sort_key,\n",
        "    sort_within_batch=True\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGYa4u1HN9on"
      },
      "source": [
        "### Creating a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LWvUzUBMnu8"
      },
      "source": [
        "class EmotionsLSTMRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_size,\n",
        "               hidden_size, output_size, num_layers,\n",
        "               bidirectional, dropout, pad_index\n",
        "               ):\n",
        "    super(EmotionsLSTMRNN, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_size,\n",
        "                                  padding_idx=pad_index)\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size = hidden_size,\n",
        "                        bidirectional=bidirectional, num_layers=num_layers,\n",
        "                        dropout = dropout\n",
        "                        )\n",
        "    self.hidden_1 = nn.Linear(hidden_size * 2, out_features=512)\n",
        "    self.hidden_2 = nn.Linear(512, out_features=256)\n",
        "    self.output_layer = nn.Linear(256, out_features=output_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, text, text_lengths):\n",
        "    embedded = self.dropout(self.embedding(text))\n",
        "    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths.to('cpu'), enforce_sorted=False)\n",
        "    packed_output, (h_0, c_0) = self.lstm(packed_embedded)\n",
        "    output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "    h_0 = self.dropout(torch.cat((h_0[-2,:,:], h_0[-1,:,:]), dim = 1))\n",
        "\n",
        "    out = self.dropout(self.hidden_1(h_0))\n",
        "    out = self.hidden_2(out)\n",
        "    return self.output_layer(out)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7BEzpyGOyWX"
      },
      "source": [
        "### Creating the Model instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBitwM2eQi37",
        "outputId": "9ebd5100-5cfb-488a-f21c-4eaaa287efb8"
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab) # # 25002\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 6\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # 0\n",
        "emotions_model = EmotionsLSTMRNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX).to(device)\n",
        "emotions_model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmotionsLSTMRNN(\n",
              "  (embedding): Embedding(15167, 100, padding_idx=1)\n",
              "  (lstm): LSTM(100, 256, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  (hidden_1): Linear(in_features=512, out_features=512, bias=True)\n",
              "  (hidden_2): Linear(in_features=512, out_features=256, bias=True)\n",
              "  (output_layer): Linear(in_features=256, out_features=6, bias=True)\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fQgn0-IQ4kd"
      },
      "source": [
        "### Counting parameters of the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEaTKAgDQwxX",
        "outputId": "adec15c3-4585-4b62-a9dd-f16da4ce2193"
      },
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(emotions_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 4,222,370\n",
            "Total tainable parameters: 4,222,370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjvZJEiAR5vc"
      },
      "source": [
        "### Loading pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoYhfS0PR0jF"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ3X6-PZR5XZ",
        "outputId": "159498a5-cd3a-459c-fc25-8c149a47bff1"
      },
      "source": [
        "emotions_model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.1233,  0.3499,  0.6173],\n",
              "        [ 0.7262,  0.0912, -0.3891,  ...,  0.0821,  0.4440, -0.7240],\n",
              "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
              "        ...,\n",
              "        [-0.1438,  0.8681, -0.7219,  ...,  0.0553, -0.4339,  0.3486],\n",
              "        [-0.0422, -0.7724, -0.9311,  ..., -0.6228,  0.7262,  0.0521],\n",
              "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Av2P6SKbd"
      },
      "source": [
        "### Zeroiing the `pad` and `unk` indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zkoG-o5R5T7",
        "outputId": "effdf774-07f5-44ad-fe01-c956e8440fd4"
      },
      "source": [
        "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token] or TEXT.vocab.stoi[\"<unk>\"]\n",
        "emotions_model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "emotions_model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "emotions_model.embedding.weight.data"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0465,  0.6197,  0.5665,  ..., -0.3762, -0.0325,  0.8062],\n",
              "        ...,\n",
              "        [-0.1438,  0.8681, -0.7219,  ...,  0.0553, -0.4339,  0.3486],\n",
              "        [-0.0422, -0.7724, -0.9311,  ..., -0.6228,  0.7262,  0.0521],\n",
              "        [-0.6644, -0.3045,  0.6151,  ...,  0.1404,  0.5788, -0.0333]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hR0X2h6Sesj"
      },
      "source": [
        "### Loss and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjPNxmwhR5Qu"
      },
      "source": [
        "optimizer = torch.optim.Adam(emotions_model.parameters())\n",
        "criterion = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGhXxngLS4gU"
      },
      "source": [
        "### Accuracy function (`categorical_accuracy`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs-y8LZvR5HO"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "  top_pred = preds.argmax(1, keepdim = True)\n",
        "  correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "  acc = correct.float() / y.shape[0]\n",
        "  return acc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdWa1ekITP3s"
      },
      "source": [
        "### Training and evaluation functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q33IueZvR5Dh"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    optimizer.zero_grad()\n",
        "    text, text_lengths = batch.text\n",
        "    predictions = model(text, text_lengths).squeeze(1)\n",
        "    loss = criterion(predictions, batch.emotion)\n",
        "    acc = categorical_accuracy(predictions, batch.emotion)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      text, text_lengths = batch.text\n",
        "      predictions = model(text, text_lengths)\n",
        "      loss = criterion(predictions, batch.emotion)\n",
        "      acc = categorical_accuracy(predictions, batch.emotion)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qla6TCZhT2uY"
      },
      "source": [
        "### Training Loop.\n",
        "\n",
        "We will create a function that will visualize our training loop `ETA` for each and every epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cmw6Zo9OUk_7"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
        "\n",
        "def visualize_training(start, end, train_loss, train_accuracy, val_loss, val_accuracy, title):\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_accuracy:.3f}', f\"{hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{val_loss:.3f}', f'{val_accuracy:.3f}', \"\" ],       \n",
        "  ]\n",
        "  table = PrettyTable([\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"])\n",
        "  table.align[\"CATEGORY\"] = 'l'\n",
        "  table.align[\"LOSS\"] = 'r'\n",
        "  table.align[\"ACCURACY\"] = 'r'\n",
        "  table.align[\"ETA\"] = 'r'\n",
        "  table.title = title\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the training loop\n",
        "\n",
        "In the train loop we are going to save the model when the previous validation loss is greater than the current validation loss."
      ],
      "metadata": {
        "id": "1RTxsxnSVkJi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_nNORR7T0cJ",
        "outputId": "61b2a233-1a19-4b21-86c9-4453a9e9679e"
      },
      "source": [
        "N_EPOCHS = 10\n",
        "MODEL_NAME = \"text-emotional-model.pt\"\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss, train_acc = train(emotions_model, train_iterator, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(emotions_model, valid_iterator, criterion)\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(emotions_model.state_dict(), MODEL_NAME)\n",
        "  end = time.time()\n",
        "  visualize_training(start, end, train_loss, train_acc, valid_loss, valid_acc, title)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.294 |    0.898 | 0:00:08.15 |\n",
            "| Validation | 0.191 |    0.922 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.242 |    0.912 | 0:00:07.92 |\n",
            "| Validation | 0.161 |    0.924 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.208 |    0.923 | 0:00:08.14 |\n",
            "| Validation | 0.142 |    0.928 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 04/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.177 |    0.932 | 0:00:08.04 |\n",
            "| Validation | 0.145 |    0.939 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 05/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.161 |    0.935 | 0:00:07.94 |\n",
            "| Validation | 0.163 |    0.931 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 06/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.153 |    0.939 | 0:00:07.98 |\n",
            "| Validation | 0.160 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 07/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.141 |    0.940 | 0:00:08.19 |\n",
            "| Validation | 0.131 |    0.934 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 08/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.132 |    0.945 | 0:00:07.91 |\n",
            "| Validation | 0.156 |    0.928 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 09/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.130 |    0.946 | 0:00:07.92 |\n",
            "| Validation | 0.144 |    0.935 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 10/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "| CATEGORY   |  LOSS | ACCURACY |        ETA |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.112 |    0.952 | 0:00:07.94 |\n",
            "| Validation | 0.154 |    0.935 |            |\n",
            "+------------+-------+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilgPdmFdZZWC"
      },
      "source": [
        "### Model Evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNxKwcnjXmTQ",
        "outputId": "70f9e989-46bf-4a0a-a0d3-2b4e8d40639b"
      },
      "source": [
        "emotions_model.load_state_dict(torch.load(MODEL_NAME))\n",
        "\n",
        "test_loss, test_acc = evaluate(emotions_model, test_iterator, criterion)\n",
        "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.125 | Test Acc: 94.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ta2Ie097ZtPQ"
      },
      "source": [
        "### Model Inference\n",
        "Making predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0iQvSoWaVX8"
      },
      "source": [
        "!pip install emoji\n",
        "import emoji\n",
        "emotions_emojis = {\n",
        "   'anger' : \":angry:\", \n",
        "   'fear': \":fearful:\", \n",
        "   'joy' : \":smile:\", \n",
        "   'love' : \":heart_eyes:\", \n",
        "   'sadness' : \":disappointed:\", \n",
        "   'surprise': \":open_mouth:\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The prediction response will be looking as follows:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"class_label\": \"sadness\",\n",
        "  \"emoji\": \"üòû\",\n",
        "  \"label\": 1,\n",
        "  \"predictions\": [\n",
        "    {\n",
        "      \"class_label\": \"joy\",\n",
        "      \"emoji\": \"üòÑ\",\n",
        "      \"label\": 0,\n",
        "      \"probability\": 0.0\n",
        "   },\n",
        "    {\n",
        "      \"class_label\": \"sadness\", \n",
        "      \"emoji\": \"üòû\", \n",
        "      \"label\": 1, \n",
        "      \"probability\": 1.0\n",
        "    },\n",
        "    {\n",
        "      \"class_label\": \"anger\", \n",
        "      \"emoji\": \"üò†\", \n",
        "      \"label\": 2, \n",
        "      \"probability\": 0.0\n",
        "    },\n",
        "    {\n",
        "      \"class_label\": \"fear\", \n",
        "      \"emoji\": \"üò®\",\n",
        "       \"label\": 3, \n",
        "       \"probability\": 0.0\n",
        "    },\n",
        "    {\n",
        "      \"class_label\": \"love\", \n",
        "      \"emoji\": \"üòç\", \n",
        "      \"label\": 4, \n",
        "      \"probability\": 0.0\n",
        "    },\n",
        "    {\n",
        "      \"class_label\": \"surprise\", \n",
        "      \"emoji\": \"üòÆ\", \n",
        "      \"label\": 5, \n",
        "      \"probability\": 0.0\n",
        "      }\n",
        "  ],\n",
        "  \"probability\": 1.0,\n",
        "  \"sentence\": \"im updating my blog because i feel shitty.\"}\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "-TVNFMwGWj_R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xroYKDwsZiGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac9f8ef4-7036-44d2-fc03-6f48f8752d1f"
      },
      "source": [
        "import spacy\n",
        "import en_core_web_sm\n",
        "nlp = en_core_web_sm.load()\n",
        "classes = LABEL.vocab.itos\n",
        "\n",
        "classes"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joy', 'sadness', 'anger', 'fear', 'love', 'surprise']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_emotion(model, sentence, min_len = 5):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
        "    if len(tokenized) < min_len:\n",
        "        tokenized += ['<pad>'] * (min_len - len(tokenized))\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    length =  [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    probabilities = F.softmax(model(tensor, length_tensor), dim=1).detach().cpu().numpy().squeeze()\n",
        "    prediction = np.argmax(probabilities, axis=0)\n",
        "\n",
        "    all_preds = [\n",
        "        {\n",
        "        'label': i,\n",
        "        'class_label': classes[i],\n",
        "        'probability': np.round(probabilities[i], 2),\n",
        "        'emoji': emoji.emojize(emotions_emojis[classes[i]], language='en', use_aliases=True)\n",
        "        } for i, _ in enumerate(probabilities)\n",
        "    ]\n",
        "\n",
        "    res ={\n",
        "        \"sentence\": sentence,\n",
        "        'label': prediction,\n",
        "        'class_label': classes[prediction],\n",
        "        'probability': np.round(probabilities[prediction], 2),\n",
        "        'predictions': all_preds,\n",
        "        'emoji': emoji.emojize(emotions_emojis[classes[prediction]], language='en', use_aliases=True)\n",
        "    }\n",
        "\n",
        "    return res"
      ],
      "metadata": {
        "id": "Ua0vNMA8WzvR"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRZQtawkegl1"
      },
      "source": [
        "### Sadness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwj7PF8hb4X2",
        "outputId": "5c6c3aff-7d88-4d01-c0ef-59bcbe46af2c"
      },
      "source": [
        "predict_emotion(emotions_model, \"im updating my blog because i feel shitty.\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_label': 'sadness',\n",
              " 'emoji': 'üòû',\n",
              " 'label': 1,\n",
              " 'predictions': [{'class_label': 'joy',\n",
              "   'emoji': 'üòÑ',\n",
              "   'label': 0,\n",
              "   'probability': 0.0},\n",
              "  {'class_label': 'sadness', 'emoji': 'üòû', 'label': 1, 'probability': 1.0},\n",
              "  {'class_label': 'anger', 'emoji': 'üò†', 'label': 2, 'probability': 0.0},\n",
              "  {'class_label': 'fear', 'emoji': 'üò®', 'label': 3, 'probability': 0.0},\n",
              "  {'class_label': 'love', 'emoji': 'üòç', 'label': 4, 'probability': 0.0},\n",
              "  {'class_label': 'surprise', 'emoji': 'üòÆ', 'label': 5, 'probability': 0.0}],\n",
              " 'probability': 1.0,\n",
              " 'sentence': 'im updating my blog because i feel shitty.'}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDTiOSS3erTD"
      },
      "source": [
        "### Fear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5hrWfjFcAsS",
        "outputId": "21b56be5-a472-4b06-887f-06c27b362a9c"
      },
      "source": [
        "predict_emotion(emotions_model, \"i am feeling apprehensive about it but also wildly excited\")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_label': 'fear',\n",
              " 'emoji': 'üò®',\n",
              " 'label': 3,\n",
              " 'predictions': [{'class_label': 'joy',\n",
              "   'emoji': 'üòÑ',\n",
              "   'label': 0,\n",
              "   'probability': 0.0},\n",
              "  {'class_label': 'sadness', 'emoji': 'üòû', 'label': 1, 'probability': 0.0},\n",
              "  {'class_label': 'anger', 'emoji': 'üò†', 'label': 2, 'probability': 0.0},\n",
              "  {'class_label': 'fear', 'emoji': 'üò®', 'label': 3, 'probability': 1.0},\n",
              "  {'class_label': 'love', 'emoji': 'üòç', 'label': 4, 'probability': 0.0},\n",
              "  {'class_label': 'surprise', 'emoji': 'üòÆ', 'label': 5, 'probability': 0.0}],\n",
              " 'probability': 1.0,\n",
              " 'sentence': 'i am feeling apprehensive about it but also wildly excited'}"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLPx7Wt-e9j2"
      },
      "source": [
        "### Joy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSHjVNGwd_hA",
        "outputId": "6697cb2b-d1af-45cd-df0e-05c0eb2c92c7"
      },
      "source": [
        "predict_emotion(emotions_model, \"i feel a little mellow today.\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_label': 'joy',\n",
              " 'emoji': 'üòÑ',\n",
              " 'label': 0,\n",
              " 'predictions': [{'class_label': 'joy',\n",
              "   'emoji': 'üòÑ',\n",
              "   'label': 0,\n",
              "   'probability': 1.0},\n",
              "  {'class_label': 'sadness', 'emoji': 'üòû', 'label': 1, 'probability': 0.0},\n",
              "  {'class_label': 'anger', 'emoji': 'üò†', 'label': 2, 'probability': 0.0},\n",
              "  {'class_label': 'fear', 'emoji': 'üò®', 'label': 3, 'probability': 0.0},\n",
              "  {'class_label': 'love', 'emoji': 'üòç', 'label': 4, 'probability': 0.0},\n",
              "  {'class_label': 'surprise', 'emoji': 'üòÆ', 'label': 5, 'probability': 0.0}],\n",
              " 'probability': 1.0,\n",
              " 'sentence': 'i feel a little mellow today.'}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwfwluRZfAKO"
      },
      "source": [
        "### Surprise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Py05l1pBd_Z2",
        "outputId": "4c7cca41-16be-4218-8e1b-43904b2dea9c"
      },
      "source": [
        "predict_emotion(emotions_model, \"i feel shocked and sad at the fact that there are so many sick people.\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_label': 'surprise',\n",
              " 'emoji': 'üòÆ',\n",
              " 'label': 5,\n",
              " 'predictions': [{'class_label': 'joy',\n",
              "   'emoji': 'üòÑ',\n",
              "   'label': 0,\n",
              "   'probability': 0.0},\n",
              "  {'class_label': 'sadness', 'emoji': 'üòû', 'label': 1, 'probability': 0.0},\n",
              "  {'class_label': 'anger', 'emoji': 'üò†', 'label': 2, 'probability': 0.0},\n",
              "  {'class_label': 'fear', 'emoji': 'üò®', 'label': 3, 'probability': 0.02},\n",
              "  {'class_label': 'love', 'emoji': 'üòç', 'label': 4, 'probability': 0.0},\n",
              "  {'class_label': 'surprise', 'emoji': 'üòÆ', 'label': 5, 'probability': 0.98}],\n",
              " 'probability': 0.98,\n",
              " 'sentence': 'i feel shocked and sad at the fact that there are so many sick people.'}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBYZw3NvfGEJ"
      },
      "source": [
        "### Love"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52BZlLjud_Vy",
        "outputId": "2533de43-b600-4a17-ee4e-7fb11e03fc0f"
      },
      "source": [
        "predict_emotion(emotions_model, \"i want each of you to feel my gentle embrace.\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_label': 'love',\n",
              " 'emoji': 'üòç',\n",
              " 'label': 4,\n",
              " 'predictions': [{'class_label': 'joy',\n",
              "   'emoji': 'üòÑ',\n",
              "   'label': 0,\n",
              "   'probability': 0.02},\n",
              "  {'class_label': 'sadness', 'emoji': 'üòû', 'label': 1, 'probability': 0.0},\n",
              "  {'class_label': 'anger', 'emoji': 'üò†', 'label': 2, 'probability': 0.0},\n",
              "  {'class_label': 'fear', 'emoji': 'üò®', 'label': 3, 'probability': 0.0},\n",
              "  {'class_label': 'love', 'emoji': 'üòç', 'label': 4, 'probability': 0.98},\n",
              "  {'class_label': 'surprise', 'emoji': 'üòÆ', 'label': 5, 'probability': 0.0}],\n",
              " 'probability': 0.98,\n",
              " 'sentence': 'i want each of you to feel my gentle embrace.'}"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCFQ1N6XfIWi"
      },
      "source": [
        "### Anger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWSblQCmeK0K",
        "outputId": "c15a7fd4-736a-428e-a11d-e6b4477d6d31"
      },
      "source": [
        "predict_emotion(emotions_model, \"i feel like my irritable sensitive combination skin has finally met it s match.\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'class_label': 'anger',\n",
              " 'emoji': 'üò†',\n",
              " 'label': 2,\n",
              " 'predictions': [{'class_label': 'joy',\n",
              "   'emoji': 'üòÑ',\n",
              "   'label': 0,\n",
              "   'probability': 0.0},\n",
              "  {'class_label': 'sadness', 'emoji': 'üòû', 'label': 1, 'probability': 0.0},\n",
              "  {'class_label': 'anger', 'emoji': 'üò†', 'label': 2, 'probability': 1.0},\n",
              "  {'class_label': 'fear', 'emoji': 'üò®', 'label': 3, 'probability': 0.0},\n",
              "  {'class_label': 'love', 'emoji': 'üòç', 'label': 4, 'probability': 0.0},\n",
              "  {'class_label': 'surprise', 'emoji': 'üòÆ', 'label': 5, 'probability': 0.0}],\n",
              " 'probability': 1.0,\n",
              " 'sentence': 'i feel like my irritable sensitive combination skin has finally met it s match.'}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading the model\n",
        "\n",
        "Now we can download and save the model as a static file."
      ],
      "metadata": {
        "id": "u8zEqjNKZ5wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(MODEL_NAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "j3usqQvFaBHc",
        "outputId": "19607c58-98dd-4c71-ba86-b0d7170e2cfa"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b7622255-7825-4381-8a34-7e9d70e7167b\", \"text-emotional-model.pt\", 16893263)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading and saving the vocabulary\n",
        "\n",
        "Now we can download and save the `vocabulary` as a `json` file."
      ],
      "metadata": {
        "id": "8_Szws9haUk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = dict(TEXT.vocab.stoi)\n",
        "\n",
        "vocab_path = \"text_vocab.json\"\n",
        "\n",
        "with open(vocab_path, \"w\") as f:\n",
        "  json.dump(vocab, f, indent=2)\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJaAUKP1alhN",
        "outputId": "b3252ab5-b90c-4946-d6ae-feb9a12c095c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(vocab_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "QqjfX_uSa9rJ",
        "outputId": "d68844ad-57bf-475d-a23e-e37c1ab382e1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_399f1394-d704-4cdb-b0b1-720241d2f573\", \"text_vocab.json\", 323721)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OxHOg3fYbcZO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}